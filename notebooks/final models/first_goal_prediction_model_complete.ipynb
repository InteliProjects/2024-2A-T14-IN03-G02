{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Modelo de Previsão do Primeiro Jogador a Marcar Gol com Base em Ataque e Defesa\n","\n","O notebook [modelo_primeiro_gol.ipynb](./first_goal_prediction_model_complete.ipynb) é o ponto central para a criação de um modelo preditivo voltado para identificar qual time marcará o primeiro gol em uma partida. Este modelo se baseia em dados históricos da Série A do Campeonato Brasileiro, abrangendo informações sobre partidas, jogadores, equipes e ligas. O objetivo principal é prever qual time sairá na frente no placar durante um jogo.\n","\n","A predição do primeiro gol é particularmente relevante para estratégias de jogo e análises táticas, uma vez que sair na frente pode influenciar significativamente o comportamento das equipes ao longo da partida. Com isso em mente, o notebook utiliza técnicas de machine learning para desenvolver um modelo que pode fornecer informações sobre quais times têm maiores chances de iniciar a contagem de gols em uma partida."]},{"cell_type":"markdown","metadata":{},"source":["### 1. Importação de Bibliotecas e Módulos\n","\n","Nesta célula, são importadas as bibliotecas e módulos necessários para a construção e avaliação do modelo preditivo de quem fará o primeiro gol em uma partida. A seguir, é detalhado cada uma das bibliotecas e módulos importados e sua função no projeto:\n","\n","**Bibliotecas Importadas**\n","\n","- **pandas**: Biblioteca essencial para a manipulação de dados, permitindo a leitura, transformação e análise dos dados em estruturas chamadas DataFrames. É utilizada para carregar e manipular o conjunto de dados das partidas.\n","- **numpy**: Usada para operações matemáticas e manipulação de arrays, facilitando cálculos numéricos e transformações nos dados, como o tratamento de valores faltantes.\n","  \n","**Módulos Importados do Scikit-learn**\n","\n","- **SVC (Support Vector Classifier)**: Classificador de máquinas de vetores de suporte, utilizado para encontrar a melhor fronteira de decisão entre classes e prever qual time marcará o primeiro gol. O SVC é especialmente útil para problemas com dados de alta dimensionalidade.\n","\n","- **train_test_split**: Função que divide o dataset em conjuntos de treino e teste, garantindo que o modelo seja treinado com uma parte dos dados e avaliado com outra. Isso ajuda a evitar o overfitting e proporciona uma estimativa mais precisa do desempenho do modelo em novos dados.\n","\n","- **StandardScaler**: Utilizado para padronizar os dados, ajustando-os para que tenham média zero e desvio padrão um. A padronização é importante para algoritmos como SVC, que são sensíveis às diferentes escalas das variáveis.\n","\n","- **SimpleImputer**: Ferramenta para lidar com valores ausentes no dataset, substituindo-os por um valor especificado (como a média ou mediana). Isso garante que os modelos possam ser treinados mesmo quando há dados incompletos.\n","\n","- **Metrics (accuracy_score, f1_score)**: Métricas utilizadas para avaliar o desempenho do modelo. \n","\n","  - **accuracy_score**: Mede a proporção de previsões corretas, sendo útil para uma visão geral do desempenho.\n","  \n","  - **f1_score**: Média harmônica entre precisão e recall, útil em cenários onde há desbalanceamento entre as classes, como é o caso de prever o primeiro gol.\n","\n","Essas importações preparam o ambiente para a construção do modelo, facilitando o manuseio dos dados e permitindo que o processo de treinamento e avaliação seja feito de forma eficiente."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Imports necessários\n","import pandas as pd\n","import numpy as np\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import accuracy_score, f1_score"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Carregamento e Preparação dos Dados\n","\n","Nesta célula, é realizado o carregamento e a preparação inicial dos dados que serão utilizados para treinar o modelo de previsão de quem marcará o primeiro gol em uma partida. A seguir, foi detalhado cada etapa desse processo:\n","\n","**Passo a Passo da Célula**\n","\n","1. **Carregamento do Dataset (`players_score.csv`)**\n","\n","   - **Descrição:** A função `pd.read_csv()` da biblioteca `pandas` é utilizada para carregar o arquivo `players_score.csv`, que contém informações detalhadas sobre o desempenho dos jogadores.\n","   - **Resultado:** O dataset `df` é carregado e contém dados como gols, minutos por gol, xG (expected goals) e outras estatísticas dos jogadores.\n","\n","2. **Definição das Principais Colunas de Features**\n","\n","   - **Descrição:** Foi criada a lista `top_feature_columns` que define as principais variáveis preditoras que serão utilizadas no modelo. As colunas selecionadas incluem:\n","     - **`goals_overall`**: Total de gols marcados pelo jogador.\n","     - **`min_per_goal_overall`**: Minutos em média que o jogador leva para marcar um gol.\n","     - **`xg_total_overall`**: Total de gols esperados (xG) do jogador, uma métrica que quantifica a qualidade das finalizações.\n","     - **`goals_away`**: Total de gols marcados pelo jogador em partidas fora de casa.\n","     - **`goals_per_90_overall`**: Média de gols marcados por 90 minutos jogados pelo jogador.\n","   - **Objetivo:** Selecionar as variáveis que têm maior potencial de influenciar a previsão de quem fará o primeiro gol em uma partida.\n","\n","3. **Preparação dos Dados (Separação das Features e Rótulo)**\n","\n","   - **Descrição:** Os dados foram divididos em variáveis explicativas (`X`) e a variável alvo (`y`):\n","     - **`X`**: Conjunto de dados contendo as features, excluindo a coluna `first_goal` (que indica quem fez o primeiro gol), além de `full_name` e `Current Club`, que não são relevantes para a modelagem.\n","     - **`y`**: Variável alvo que armazena a coluna `first_goal`, indicando qual jogador marcou o primeiro gol.\n","   - **Resultado:** \n","     - **`X`**: Contém todas as features selecionadas que serão utilizadas para treinar o modelo.\n","     - **`y`**: Contém as informações sobre quem marcou o primeiro gol, que o modelo tentará prever.\n","\n","**Resultados Obtidos**\n","\n","- **Carregamento Completo do Dataset**: O arquivo `players_score.csv` foi carregado com sucesso, e as colunas principais foram definidas para o treinamento do modelo.\n","- **Seleção e Preparação de Variáveis**: As variáveis explicativas (features) e a variável alvo foram separadas, preparando os dados para a próxima etapa de pré-processamento e treinamento do modelo."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Carregando o dataset\n","df = pd.read_csv('players_score.csv')\n","\n","# Definindo as principais colunas de features\n","top_feature_columns = ['goals_overall', 'min_per_goal_overall', 'xg_total_overall', 'goals_away', 'goals_per_90_overall']\n","\n","# Preparando os dados\n","X = df.drop(columns=['first_goal', 'full_name', 'Current Club'])\n","y = df['first_goal']\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Processamento e Divisão dos Dados\n","\n","Nesta célula, realizamos o pré-processamento dos dados, transformando as variáveis categóricas em numéricas e normalizando os valores para otimizar o desempenho do modelo. Em seguida, os dados são divididos em conjuntos de treino e teste, garantindo uma avaliação justa do modelo. Abaixo estão os detalhes de cada etapa:\n","\n","**Passo a Passo da Célula**\n","\n","1. **Codificação de Variáveis Categóricas com `pd.get_dummies()`**\n","\n","   - **Descrição:** A função `pd.get_dummies()` é utilizada para converter variáveis categóricas em variáveis dummy (variáveis binárias). O parâmetro `drop_first=True` é utilizado para evitar multicolinearidade, eliminando a primeira coluna de cada variável categórica.\n","   - **Resultado:** A variável `X_encoded` contém os dados transformados, com todas as variáveis categóricas convertidas em variáveis numéricas.\n","\n","2. **Tratamento de Valores Faltantes com `SimpleImputer`**\n","\n","   - **Descrição:** O objeto `SimpleImputer` da biblioteca `sklearn` é configurado para substituir valores ausentes pela média das colunas. O método `fit_transform()` é aplicado aos dados codificados para preencher valores faltantes.\n","   - **Resultado:** A variável `X_imputed` contém os dados sem valores ausentes, garantindo que o modelo não encontre problemas ao lidar com valores nulos.\n","\n","3. **Normalização dos Dados com `StandardScaler`**\n","\n","   - **Descrição:** A normalização é feita usando o `StandardScaler`, que ajusta os dados para que tenham média zero e desvio padrão igual a um. Isso ajuda a equilibrar a escala das diferentes variáveis, especialmente importante para algoritmos que são sensíveis à escala dos dados.\n","   - **Resultado:** A variável `X_scaled` contém os dados normalizados, prontos para serem usados no treinamento do modelo.\n","\n","4. **Divisão dos Dados em Conjuntos de Treino e Teste**\n","\n","   - **Descrição:** A função `train_test_split()` é utilizada para dividir os dados normalizados em conjuntos de treino e teste, na proporção de 80% para treino e 20% para teste. O parâmetro `random_state=42` garante que a divisão seja reprodutível, mantendo a consistência dos resultados em diferentes execuções.\n","   - **Resultado:** \n","     - **`X_train`** e **`y_train`**: Conjuntos de treino que serão usados para ajustar os parâmetros do modelo.\n","     - **`X_test`** e **`y_test`**: Conjuntos de teste que serão utilizados para avaliar o desempenho do modelo em novos dados.\n","\n","**Resultados Obtidos**\n","\n","- **Codificação e Normalização Completas**: As variáveis categóricas foram transformadas em numéricas, valores ausentes foram tratados e os dados foram normalizados, garantindo uma preparação adequada para a modelagem.\n","- **Divisão dos Dados**: Os dados foram divididos em conjuntos de treino e teste, permitindo que o modelo seja treinado em um subconjunto e testado em outro, assegurando uma avaliação justa do desempenho preditivo."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["\n","# Processamento de dados\n","X_encoded = pd.get_dummies(X, drop_first=True)\n","imputer = SimpleImputer(strategy='mean')\n","scaler = StandardScaler()\n","X_imputed = imputer.fit_transform(X_encoded)\n","X_scaled = scaler.fit_transform(X_imputed)\n","\n","# Dividindo os dados em treino e teste\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 4. Simulação de Características e Ajuste do Modelo\n","\n","Nesta célula, foi realizada uma simulação de características defensivas para enriquecer o conjunto de treino e, em seguida, ajustar um modelo de **Support Vector Machine (SVM)** ponderado para lidar com classes desbalanceadas. Abaixo estão os detalhes de cada etapa:\n","\n","**Passo a Passo da Célula**\n","\n","1. **Simulação de Características Defensivas para o Conjunto de Treino**\n","\n","   - **Descrição:** Utiliza-se a função `np.random.uniform()` para gerar características defensivas simuladas para o conjunto de treino. As características são valores aleatórios gerados entre 0.5 e 1.5, criando uma matriz de dimensões que correspondem ao número de amostras de treino (`X_train.shape[0]`) e 7 novas características.\n","   - **Resultado:** A matriz `train_defense_simulation` contém as novas características simuladas, que são então concatenadas com as características originais do conjunto de treino (`X_train`) usando `np.hstack()`, resultando em `X_train_full_defensive`, que é um conjunto de treino enriquecido com novas informações.\n","\n","2. **Ajuste do Modelo Ponderado com `SVC`**\n","\n","   - **Descrição:** Um modelo de **Support Vector Machine (SVM)** é inicializado e ajustado para lidar com dados desbalanceados, utilizando o parâmetro `class_weight='balanced'`, que atribui pesos às classes inversamente proporcionais às suas frequências no conjunto de treino. Os parâmetros do modelo são:\n","     - **`C=1`**: Define o grau de penalização dos erros de classificação, onde valores maiores tornam o modelo mais rígido.\n","     - **`kernel='rbf'`**: Utiliza uma função de kernel radial basis function (RBF), que ajuda a capturar relações não lineares nos dados.\n","     - **`gamma=0.01`**: Define a amplitude do kernel RBF, influenciando a forma como o modelo separa os dados.\n","   - **Resultado:** O modelo `svm_model_weighted` é treinado usando o conjunto de treino enriquecido (`X_train_full_defensive`) e o rótulo `y_train`, sendo preparado para realizar previsões.\n","\n","3. **Extração do Número de Colunas do Conjunto de Treino Completo**\n","\n","   - **Descrição:** O número de colunas utilizadas no conjunto de treino enriquecido (`X_train_full_defensive`) é extraído e armazenado em `train_columns`. Esse valor é importante para garantir que o conjunto de teste e as futuras predições tenham a mesma estrutura.\n","   - **Resultado:** A variável `train_columns` armazena o número de colunas (características) utilizadas no treinamento do modelo, facilitando a verificação da consistência dos dados entre treino e teste.\n","\n","**Resultados Obtidos**\n","\n","- **Enriquecimento do Conjunto de Treino**: A adição de características defensivas simuladas permite ao modelo considerar novas variáveis relacionadas ao desempenho defensivo dos times, potencialmente melhorando a precisão das previsões.\n","- **Modelo Ponderado Ajustado**: O modelo SVM ponderado foi treinado com dados balanceados, aumentando sua capacidade de lidar com classes desbalanceadas, como o time que marca o primeiro gol.\n","- **Consistência dos Dados**: A extração do número de colunas usadas no treinamento garante que os conjuntos de treino e teste estejam alinhados em termos de estrutura de dados, evitando problemas durante as predições."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Simulando características defensivas para o conjunto de treino\n","train_defense_simulation = np.random.uniform(0.5, 1.5, size=(X_train.shape[0], 7))\n","X_train_full_defensive = np.hstack((X_train, train_defense_simulation))\n","\n","# Ajustando o modelo ponderado\n","svm_model_weighted = SVC(C=1, kernel='rbf', gamma=0.01, class_weight='balanced')\n","svm_model_weighted.fit(X_train_full_defensive, y_train)\n","\n","# Extraindo as colunas usadas no treinamento (X_train_full_defensive)\n","train_columns = X_train_full_defensive.shape[1]"]},{"cell_type":"markdown","metadata":{},"source":["### 5. Função para Prever o Jogador com Maior Probabilidade de Marcar o Primeiro Gol\n","\n","Nesta célula, implementa-se uma função chamada `test_weighted_model_adjusted` para prever qual jogador tem maior probabilidade de marcar o primeiro gol em um confronto específico. A função utiliza o modelo ajustado de **Support Vector Machine (SVM)** e garante que as colunas do conjunto de teste sejam consistentes com as do treinamento. Abaixo estão os detalhes de cada passo:\n","\n","**Passo a Passo da Função**\n","\n","1. **Filtragem dos Times com Base na Entrada do Usuário**\n","\n","   - **Descrição:** A função recebe como entrada os nomes dos times da casa (`user_home_team`) e visitante (`user_away_team`). Utilizando essas entradas, ela filtra o dataset `df` para encontrar o registro do jogo específico entre esses dois times. A filtragem é feita com a função `str.contains()` para garantir que a busca não seja sensível a maiúsculas ou minúsculas.\n","   - **Resultado:** A variável `game_df` armazena os dados do jogo específico. Caso nenhum dado correspondente seja encontrado, a função exibe uma mensagem informando que não há dados disponíveis para os times inseridos.\n","\n","2. **Simulação de Características Defensivas para o Jogo**\n","\n","   - **Descrição:** Utiliza-se a função `np.random.uniform()` para gerar características defensivas simuladas para o jogo, assim como feito durante o treinamento. Esses valores são gerados entre 0.5 e 1.5, resultando em uma matriz que é concatenada com as características originais do jogo.\n","   - **Resultado:** A matriz `game_defense_simulation` contém as novas características defensivas simuladas, garantindo que as condições de teste sejam consistentes com as do treinamento.\n","\n","3. **Processamento dos Dados do Jogo**\n","\n","   - **Descrição:** O conjunto de features relevantes para o jogo é selecionado com `top_feature_columns`, e as mesmas etapas de pré-processamento aplicadas ao conjunto de treino são executadas no conjunto de teste:\n","     - **Codificação de Variáveis Categóricas**: As colunas categóricas são transformadas em variáveis dummy usando `pd.get_dummies()`.\n","     - **Realinhamento de Colunas**: As colunas de `X_game_test_encoded` são reindexadas para que correspondam às colunas utilizadas durante o treinamento, preenchendo com zeros caso alguma coluna não esteja presente.\n","     - **Imputação e Escalonamento**: Os dados são imputados usando o `SimpleImputer` treinado e escalados com o `StandardScaler` treinado, garantindo consistência nos valores numéricos.\n","   - **Resultado:** A variável `X_game_test_scaled` contém os dados do jogo, escalados e preparados para previsão.\n","\n","4. **Concatenar Características Defensivas ao Conjunto de Teste**\n","\n","   - **Descrição:** As características defensivas simuladas são concatenadas ao conjunto de teste escalado, usando `np.hstack()`, resultando em um conjunto de teste que inclui tanto as características ofensivas quanto as defensivas.\n","   - **Resultado:** A variável `X_game_test_defensive` contém o conjunto de dados completo para o jogo, preparado para ser utilizado pelo modelo SVM ajustado.\n","\n","5. **Verificação de Consistência de Colunas**\n","\n","   - **Descrição:** Antes de realizar a previsão, a função verifica se o número de colunas de `X_game_test_defensive` é igual ao número de colunas utilizadas durante o treinamento. Isso garante que a estrutura dos dados de teste esteja compatível com o modelo treinado.\n","   - **Resultado:** Caso o número de colunas não seja compatível, a função exibe uma mensagem de erro e termina a execução, evitando que sejam realizadas previsões inconsistentes.\n","\n","6. **Previsão com o Modelo Ajustado**\n","\n","   - **Descrição:** A função `decision_function()` do modelo SVM é utilizada para calcular as pontuações de decisão para cada jogador no jogo. Essas pontuações representam a confiança do modelo sobre a probabilidade de cada jogador marcar o primeiro gol.\n","   - **Resultado:** A variável `y_prob_game_weighted` armazena as pontuações de decisão do modelo, que são adicionadas ao DataFrame `game_df` na coluna `first_goal_prob_weighted`.\n","\n","7. **Ordenação e Seleção do Jogador com Maior Probabilidade**\n","\n","   - **Descrição:** O DataFrame `game_df` é ordenado com base na coluna `first_goal_prob_weighted` em ordem decrescente, de forma que os jogadores com maior probabilidade de marcar estejam no topo da lista. O jogador mais provável é selecionado usando `iloc[0]`.\n","   - **Resultado:** A função exibe uma mensagem com o nome do jogador mais provável de marcar o primeiro gol, além de exibir o clube ao qual ele pertence.\n","\n","**Exemplo de Uso da Função**\n","\n","- **Input:** A função é chamada com `'Corinthians'` como time da casa e `'Botafogo'` como time visitante.\n","- **Output:** A função retorna o jogador mais propenso a marcar o primeiro gol, informando o nome do jogador e o clube atual.\n","\n","**Resultados Obtidos**\n","\n","- **Simulação Realista:** A adição de características defensivas simuladas proporciona uma visão mais realista do comportamento dos times, aumentando a precisão das previsões.\n","- **Modelo Ajustado e Testado:** A função aplica os mesmos procedimentos de pré-processamento nos dados de teste, garantindo que as previsões sejam consistentes com o que o modelo aprendeu durante o treinamento.\n","- **Previsão do Jogador Mais Provável:** A função entrega o jogador mais provável de marcar o primeiro gol no jogo, auxiliando em análises táticas e previsões esportivas."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Função para prever o jogador com maior probabilidade de marcar o primeiro gol, garantindo as colunas certas\n","def test_weighted_model_adjusted(user_home_team, user_away_team):\n","    # Filtrar os times baseados na entrada do usuário\n","    game_df = df[\n","        (df['home_team'].str.contains(user_home_team, case=False)) &\n","        (df['away_team'].str.contains(user_away_team, case=False))\n","    ]\n","\n","    if game_df.empty:\n","        print(\"Os times inseridos não têm dados disponíveis.\")\n","        return\n","\n","    # Simular características defensivas\n","    game_defense_simulation = np.random.uniform(0.5, 1.5, size=(game_df.shape[0], 7))\n","    \n","    # Processar dados\n","    X_game_test = game_df[top_feature_columns]\n","    \n","    # Aplicar os mesmos tratamentos do treino (imputer e scaler) para garantir consistência\n","    X_game_test_encoded = pd.get_dummies(X_game_test, drop_first=True)\n","    \n","    # Alinhar as colunas entre treino e teste\n","    X_game_test_encoded = X_game_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n","    \n","    X_game_test_imputed = imputer.transform(X_game_test_encoded)\n","    X_game_test_scaled = scaler.transform(X_game_test_imputed)\n","    \n","    # Concatenar as características defensivas\n","    X_game_test_defensive = np.hstack((X_game_test_scaled, game_defense_simulation))\n","    \n","    # Garantir que o conjunto de teste tenha as colunas certas\n","    if X_game_test_defensive.shape[1] != train_columns:\n","        print(\"O número de colunas no teste não corresponde ao número de colunas no treino.\")\n","        return\n","    \n","    # Fazer previsões com o modelo ajustado\n","    y_prob_game_weighted = svm_model_weighted.decision_function(X_game_test_defensive)\n","    game_df['first_goal_prob_weighted'] = y_prob_game_weighted\n","    game_df_sorted = game_df[['home_team', 'away_team', 'full_name', 'Current Club', 'first_goal_prob_weighted']].sort_values(by='first_goal_prob_weighted', ascending=False)\n","    \n","    # Pegar o jogador mais provável\n","    top_player = game_df_sorted.iloc[0]\n","    print(f'O jogador mais propenso a marcar gol é {top_player[\"full_name\"]} do time {top_player[\"Current Club\"]}')\n","\n","# Exemplo de uso corrigido\n","test_weighted_model_adjusted('Corinthians', 'Botafogo')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":2}
